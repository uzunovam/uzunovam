---
layout: post
title: "Kevin Zollman on game theory and epistemology"
date: 2020-07-22
---
<p>Kevin J. S. Zollman (2021). <a href="https://doi.org/10.1007/s11098-020-01480-5" target="_blank" rel="noopener">The theory of games as a tool for the espitemologist</a>. <cite>Philosophical Studies</cite> 178 (4): 1381–1401.</p>

<p>Can purely epistemic situations be situations of strategic interaction? Most certainly yes, argues Kevin Zollman in a thought-provoking new paper. There is much in this paper that is fascinating, including multiple philosophical claims, suppositions, and arguments relevant to many disciplines. Most of these will be set aside here. The focus here will rather be on the relation between the first substantive part of the paper (section two) and the second (section three). Section two builds up a framework for generating strategic considerations in ‘purely’ epistemic situations. It also describes a specific class of situations that amount to Prisoner’s Dilemma games. Section three builds up a slightly different framework and generates, within this framework, further stylised classic games, such as a Stag Hunt and a Coordination game. (And a Prisoner’s Delight game.) There is one class of games that is not generated in this framework: Chicken games. (Zollman is well aware of this and notes it in a footnote, 1392n17.) I want to know where this difficulty comes from: is this a purely pragmatic difficulty, such that if one were to keep trying, one could generate Chicken games? Or is there a more fundamental difference between the kind of conditions that generate Stag Hunt, Coordination, and Prisoner’s Dilemma (and Delight) games, on the one hand, and Chicken games, on the other? It seems to me that it is rather the latter.</p>

<p>Here’s the strategy. To get at the root of this (possible) inconsistency, we’ll approach this from a more general level, thinking about the kind of general conditions that allow for various types of games. If it turns out that the conditions allowing for some class of games are inconsistent with the conditions allowing for a different class of games, we must conclude that generating both classes within the same set of conditions is impossible. Within Zollman’s framework in section two, this translates to: if the properties that joint accuracy functions must satisfy to generate one class of (Stag Hunt and Coordination) games are inconsistent with the properties that joint accuracy functions must satisfy to generate another class of (Chicken) games, then these two classes of games cannot be generated by the same class of joint accuracy functions. To understand this, we need some preliminaries explaining Zollman’s framework in section two. And then we need to generate, within that framework, the types of games generated in the paper within the framework of section three.</p>

<p style="padding-left:100px;"><u>Individual epistemic decision-making</u></p>

<p>Here’re the bare preliminaries:</p>

<p style="padding-left:100px;">“Suppose a single proposition \(p\) which an agent assigns a credence \(c\). If \(p\) turns out to be true, our agent is assigned an accuracy score of \(S(c, 1)\) and if it turns out to be false \(S(c, 0)\). [\(\dots\)]</p>
<p style="padding-left:100px;">Our agent has credence \(c\) and she is evaluating the expected accuracy of alternative credence in the same proposition, \(c^{\prime}\). She expects \(c^{\prime}\) would receive the score: \(E(c^{\prime}, c) = cS(c^{\prime}, 1) + (1-c)S(c^{\prime}, 0)\).” (1384)</p>

<p>A key concept in this framework is the idea of a ‘proper scoring rule’. It is defined as follows:</p>

<p style="padding-left:100px;"><strong>Proper scoring rule</strong>. Let \(S(c, y)\) with \(c \in [0, 1]\) and \(y \in \{0, 1\}\) be a scoring rule. And let \(E(c^{\prime}, c)\) with \(c, c^{\prime} \in [0,1]\) be an expectation function that yields the expected accuracy of credence \(c^{\prime}\), that is, \(E(c^{\prime}, c) = E(c, S(c^{\prime}, 1), S(c^{\prime}, 0))\). Then \(S\) is a proper scoring rule if for all credences \(c\):</p>
<p style="padding-left:100px;">\(c = \text{argmax}_{c^{\prime} \in [0,1]} E(c^{\prime}, c)\)</p>

<p>This means that for all \(c\) and all \(c^{\prime} \neq c\), we have \(E(c, c) \geq E(c^{\prime}, c)\), with strict inequality yielding strict propriety. Or, intuitively, a scoring rule is proper if an agent’s credence maximises the agent’s expected accuracy, <cite>relative to that credence</cite>.</p>

<p style="padding-left:100px;"><u>\(n\)-person epistemic decision-making</u></p>

<p>Now, all of the above describes evaluations by a single agent. So let’s introduce strategic considerations by introducing more agents. Let \(N = \{1, \dots, n\}\) be the set of agents. (The notation above will now be indexed by the respective agent \(i\).) Further, let vector \(\mathbf{x} = (x_{1}, \dots, x_{n})\) collect credences for each agent. Now, define the joint accuracy function of agent \(i\) to be a function of the expected accuracy that \(i\) assigns to each credence in \(\mathbf{x}\); that is, \(JA_{i}(\mathbf{x}, c_{i}) = JA_{i}(E_{i}(x_{1}, c_{i}), \dots, E_{i}(x_{n}, c_{i}))\). </p>

<p>With this machinery at hand, it is easy to derive a generalisation of Zollman’s Proposition 2. According to this proposition, ‘sticking to one’s own prior credence’ weakly dominates the strategy of adopting a compromise credence, given a linear joint accuracy function. In fact, it is easy to show that ‘sticking to one’s prior credence’ is a weakly dominant strategy for a large class of joint accuracy functions. (And hence weakly dominates not just adopting a compromise credence, but also adopting any other credence.)</p>

<p>As long as each agent is using a joint accuracy function that is monotonic in the agents’ expectation functions, then we have:</p>

<p style="padding-left:100px;">Suppose that, for all \(i \in N\), \(S_{i}\) is a strictly proper scoring rule. Then as long as \(JA_{i}\) is monotonic in \(E_{i}\) for all \(i \in N\), we have:</p>

<p style="padding-left:100px;">\(JA_{i}((c_{i}, \mathbf{x}_{-i}), c_{i}) \geq JA_{i}(\mathbf{x}, c_{i})\)</p>

<p style="padding-left:100px;">Where \((c_{i}, \mathbf{x}_{-i})\) is the vector of credences where \(i\)’s credence is \(c_{i}\) and everyone else’s is as in \(\mathbf{x}\).</p>

<p style="padding-left:100px;">(The inequality follows immediately from monotonicity, the fact that \(E(c_{i}, c_{i})\) and \(E(x_{i}, c_{i})\) are the only differing arguments, and the fact that, due to strict propriety, \(E(c_{i}, c_{i}) \geq E(x_{i}, c_{i})\), with a strict sign when \(x_{i} \neq c_{i}\).)</p>

<p>This more general result establishes that for a large class of monotonic joint accuracy functions, each agent has, <cite>for any possible credence the agent may hold</cite>, a weakly dominant strategy: namely, sticking to this prior credence. And this, in turn, implies that for any vector collecting the prior distribution of credences, this vector is a Nash equilibrium. That is to say, if \(\mathbf{c}\) is the vector of credences of the agents in \(N\), then \(\mathbf{c}\) is a Nash equilibrium.</p>

<p>The question now is: is \(\mathbf{c}\) a <cite>unique</cite> Nash equilibrium? The answer hinges on the kind of mononicity the joint accuracy functions satisfy. Let’s start from the strictest possible case. First, assume as before that \(S_{i}\) are strictly proper for all \(i\), so that there is a unique credence \(c\) that maximises \(E_{i}(c, c_{i})\): namely, \(c = c_{i}\). Then, consider the following property:</p>











