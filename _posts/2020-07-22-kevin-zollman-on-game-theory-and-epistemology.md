---
layout: post
title: "Kevin Zollman on game theory and epistemology"
date: 2020-07-22
---
<p>Kevin J. S. Zollman (2021). <a href="https://doi.org/10.1007/s11098-020-01480-5" target="_blank" rel="noopener">The theory of games as a tool for the espitemologist</a>. <cite>Philosophical Studies</cite> 178 (4): 1381–1401.</p>

<p>Can purely epistemic situations be situations of strategic interaction? Most certainly yes, argues Kevin Zollman in a thought-provoking new paper. There is much in this paper that is fascinating, including multiple philosophical claims, suppositions, and arguments relevant to many disciplines. Most of these will be set aside here. The focus here will rather be on the relation between the first substantive part of the paper (section two) and the second (section three). Section two builds up a framework for generating strategic considerations in ‘purely’ epistemic situations. It also describes a specific class of situations that amount to Prisoner’s Dilemma games. Section three builds up a slightly different framework and generates, within this framework, further stylised classic games, such as a Stag Hunt and a Coordination game. (And a Prisoner’s Delight game.) There is one class of games that is not generated in this framework: Chicken games. (Zollman is well aware of this and notes it in a footnote, 1392n17.) I want to know where this difficulty comes from: is this a purely pragmatic difficulty, such that if one were to keep trying, one could generate Chicken games? Or is there a more fundamental difference between the kind of conditions that generate Stag Hunt, Coordination, and Prisoner’s Dilemma (and Delight) games, on the one hand, and Chicken games, on the other? It seems to me that it is rather the latter.</p>

<p>Here’s the strategy. To get at the root of this (possible) inconsistency, we’ll approach this from a more general level, thinking about the kind of general conditions that allow for various types of games. If it turns out that the conditions allowing for some class of games are inconsistent with the conditions allowing for a different class of games, we must conclude that generating both classes within the same set of conditions is impossible. Within Zollman’s framework in section two, this translates to: if the properties that joint accuracy functions must satisfy to generate one class of (Stag Hunt and Coordination) games are inconsistent with the properties that joint accuracy functions must satisfy to generate another class of (Chicken) games, then these two classes of games cannot be generated by the same class of joint accuracy functions. To understand this, we need some preliminaries explaining Zollman’s framework in section two. And then we need to generate, within that framework, the types of games generated in the paper within the framework of section three.</p>

<p style="padding-left:100px;"><u>Individual epistemic decision-making</u></p>

<p>Here’re the bare preliminaries:</p>

<p style="padding-left:100px;">“Suppose a single proposition \(p\) which an agent assigns a credence \(c\). If \(p\) turns out to be true, our agent is assigned an accuracy score of \(S(c, 1)\) and if it turns out to be false \(S(c, 0)\). [\(\dots\)]</p>
<p style="padding-left:100px;">Our agent has credence \(c\) and she is evaluating the expected accuracy of alternative credence in the same proposition, \(c^{\prime}\). She expects \(c^{\prime}\) would receive the score: \(E(c^{\prime}, c) = cS(c^{\prime}, 1) + (1-c)S(c^{\prime}, 0)\).” (1384)</p>

<p>A key concept in this framework is the idea of a ‘proper scoring rule’. It is defined as follows:</p>

<p style="padding-left:100px;"><strong>Proper scoring rule</strong>. Let \(S(c, y)\) with \(c \in [0, 1]\) and \(y \in \{0, 1\}\) be a scoring rule. And let \(E(c^{\prime}, c)\) with \(c, c^{\prime} \in [0,1]\) be an expectation function that yields the expected accuracy of credence \(c^{\prime}\), that is, \(E(c^{\prime}, c) = E(c, S(c^{\prime}, 1), S(c^{\prime}, 0))\). Then \(S\) is a proper scoring rule if for all credences \(c\):</p>
<p style="padding-left:100px;">\(c = \text{argmax}_{c^{\prime} \in [0,1]} E(c^{\prime}, c)\)</p>

<p>This means that for all \(c\) and all \(c^{\prime} \neq c\), we have \(E(c, c) \geq E(c^{\prime}, c)\), with strict inequality yielding strict propriety. Or, intuitively, a scoring rule is proper if an agent’s credence maximises the agent’s expected accuracy, <cite>relative to that credence</cite>.</p>

<p style="padding-left:100px;"><u>\(n\)-person epistemic decision-making</u></p>

<p>Now, all of the above describes evaluations by a single agent. So let’s introduce strategic considerations by introducing more agents. Let \(N = \{1, \dots, n\}\) be the set of agents. (The notation above will now be indexed by the respective agent \(i\).) Further, let vector \(\mathbf{x} = (x_{1}, \dots, x_{n})\) collect credences for each agent. Now, define the joint accuracy function of agent \(i\) to be a function of the expected accuracy that \(i\) assigns to each credence in \(\mathbf{x}\); that is, \(JA_{i}(\mathbf{x}, c_{i}) = JA_{i}(E_{i}(x_{1}, c_{i}), \dots, E_{i}(x_{n}, c_{i}))\). </p>









