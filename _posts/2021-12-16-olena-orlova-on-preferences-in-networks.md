---
layout: post
title: "Olena Orlova on preferences in networks"
date: 2021-12-16
---
<p>Olena Orlova (2022). <a href="https://doi.org/10.1016/j.geb.2021.10.006" target="_blank" rel="noopener">Idiosyncratic preferences in games on networks</a>. <cite>Games and Economic Behavior</cite> 131: 29–50.</p>

<p>How do our social connections—or, more generally, the structure of our social networks—influence how we make decisions? The dominant approach in the theory of networks takes this to be a question <cite>exclusively</cite> about network effects. On this view, what we (optimally) do is a function of an underlying network structure: my preferences over coffee and tea, say, depend on the choice of beverage that my friends, or acquaintances, make as well as on how much, and <cite>in what way</cite>, I care about these social connections. If I like my friends, for example, then the more <cite>they</cite> drink coffee, the more likely <cite>I</cite> may be to (optimally) drink coffee as well—our actions, in this case, would be <cite>strategic complements</cite>. Alternatively, if I dislike my friends, the more they drink coffee, the more likely I may be to go for tea—a situation of <cite>strategic substitutes</cite>.</p>

<p>Understanding the network effects of individual decision making is immensely important but focusing <cite>only</cite> on these effects is a different matter. Such an approach, as Olena Orlova points out, ultimately assumes that the only source of heterogeneity between agents—relevant to decision making, that is—is that of their network position. Such an approach thus abstracts away from any non-network-related differences in our preferences. My choice of beverage may be a function of my friends’ drinking habits, but it may also depend, in part, on my (exogenously given) preferences over coffee and tea. Surprisingly, especially given the history of economic thought, attention to how the unique preferences of agents affect what they do in social networks has been sparse (see the discussion on 31 for some related work). Analysing the interaction between these two sources of agential heterogeneity is the main contribution of Orlova’s paper.</p>

<p style="padding-left:100px;"><u>The motivation</u></p>

<p>To get a sense of this contribution and why it is important, consider the following example. There are five agents, \(A\), \(B\), \(C\), \(D\), and \(E\), in a social network that can be illustrated as follows (for now, focus on the left panel; the example is adapted from the one on 38):</p>

<p style="padding-left:100px;"><img src="https://uzunovam.github.io/images/graph1.png" /></p>

<p style="padding-left:100px;"><smallcaps>figure 1</smallcaps></p>

<p>Suppose that a link between two agents refers to the existence of a friendship (as the network is undirected, friendship is reciprocal: if \(A\) is friends with \(B\), \(B\) is also friends with \(A\)). For instance, in this network, \(A\), \(B\), and \(C\) are a close-knit group where every agent is friends with every other agent, while \(C\), clearly the most popular agent, is friends with everyone. Suppose, further, that each agent may do either of two things: (1) drink coffee (indicated in blue), or (2) drink tea (indicated in red). Then consider the situation depicted in the left panel above, where \(B\) and \(C\) drink coffee and \(A\), \(D\), and \(E\) drink tea.</p>

<p>To be able to say something about individual utility in this situation, we need to know how utility is affected by one’s friendship network. Suppose that for each immediate friend who drinks the <cite>same</cite> (<cite>different</cite>) beverage, the respective agent receives a utility of \(1/3\) (\(2/3\)). Thus, in the left network above where agent \(C\) drinks coffee, \(C\)’s utility is \(2/3+1/3+2/3+2/3=7/3\). Conversely, in the right network above where \(C\) drinks tea, \(C\)’s utility is \(1/3+2/3+1/3+1/3=5/3\). Clearly, in the situation where \(A\), \(D\), and \(E\) drink tea while only \(B\) drinks coffee, \(C\) is better off drinking coffee. Notice that, in this example, \(C\) cares more about ‘mis-matching’ her action with those of her friends (‘mis-matching’ has a payoff of \(2/3\), which is bigger than the ‘matching’ payoff of \(1/3\)). We are thus in a game of strategic substitutes. That is, \(C\) is better off drinking coffee in such a situation because most of her friends are drinking tea and \(C\) prefers drinking something different. (\(C\) is friends with everyone but is a bit of a contrarian.)</p>

<p>One drawback of the utility function above is that it is entirely dependent on what Orlova calls ‘interactional utility’: the part of one’s utility function that captures network effects. It ignores however, in Orlova’s words, one’s ‘idiosyncratic utility’: the part of one’s utility function that captures one’s idiosyncratic preferences (here, over coffee and tea). Orlova’s contribution is to combine these two components in an overall utility function that captures both network and idiosyncratic effects.</p>

<p>To appreciate why combining these effects might be important, let’s now distinguish between the actions agents may take (drink coffee or tea) and their exogenously given, idiosyncratic preferences over these actions (prefer coffee or tea). Consider the following variation on the situation above:</p>

<p style="padding-left:100px;"><img src="https://uzunovam.github.io/images/graph2.png" /></p>

<p style="padding-left:100px;"><smallcaps>figure 2</smallcaps></p>

<p>Here, the colour of the outline of a node indicates the actions in the respective situation: for example, on the left, it is still the case that \(A\), \(D\), and \(E\) drink tea while \(B\) and \(C\) drink coffee. The colour of the letter in a node now indicates that agent’s idiosyncratic preference: for example, on the left, \(E\) prefers coffee (to tea) while \(A\), \(B\), \(C\), and \(D\) prefer tea (to coffee). Suppose that ‘mis-matching’ still carries a (relative) benefit of \(2/3\) while ‘matching’ yields a (relative) benefit of \(1/3\). But now further suppose that, in any situation where an agent performs the action she prefers, she gets a benefit of \(1/4\) for each of her friends; otherwise, when she does not perform her preferred action, she gets a benefit of zero. When \(C\) drinks coffee (left panel), \(C\)’s utility is \(2/3+1/3+2/3+2/3=7/3\). When \(C\) drinks her preferred beverage, tea (right panel), her utility is \(1/3+2/3+1/3+1/3+4/4=8/3\). And so \(C\) is better off drinking tea.</p>

<p>The important thing to notice here is that interactional and idiosyncratic utility may pull in different directions. \(C\) may be a contrarian but if she cared enough about her idiosyncratic tastes, then she may be better off going for what her friends do if <cite>that</cite> were what she cares about. Alternatively, \(C\) may not have strong beverage preferences—if going for her preferred drink were worth just, say, \(1/12\) per friend, \(C\) would be better off being contrarian and drinking coffee.</p>

<p>Preferences over and choices of beverage are innocent enough, but other contexts reveal how important understanding these interactional effects is. Orlova gives the example of school choice (30): in the illustration above, the agents could be parents who are friends or part of a neighbourhood; their actions could be the school (one of two) they choose for their children and their idiosyncratic preferences could be their preferences over these schools. School choice, especially among tight friendship or neighbourhood networks, has wider segregation effects—understanding when parents in a close network <cite>coordinate</cite> on the same school is essential for understanding how segregation may arise and be maintained. The two, among others, classes of games that Orlova focuses on—coordination games, where agents adopt the same action, and anti-coordination games, where agents choose different actions—are immensely relevant here.</p>

<p>In passing (30n6), Orlova mentions that idiosyncratic preferences may also be interpreted as <cite>identities</cite>. In fact, I think we can go further and interpret the whole model as a model of <cite>identity choice</cite>. The groups, broadly construed, that we decide to become members of depend both on idiosyncratic values we hold and on group effects (say, status or group benefits). Understanding the interaction between these two sources of identification is then helpful for understanding the conditions under which we end up with ‘narrow’ or ‘broad’ (or ‘multiple’) identities. (See Partha Dasgupta and Sanjeev Goyal’s <a href="https://doi.org/10.1628/jite-2019-0025" target="_blank" rel="noopener">model of narrow identities</a> and <a href="https://ejpe.org/journal/issue/view/27" target="_blank" rel="noopener">this symposium</a> on the paper.) These cases would correspond to coordination and anti-coordination games and so the bridge between Orlova’s model and <a href="https://doi.org/10.1146/annurev-economics-082019-110313" target="_blank" rel="noopener">the economic literature on identity choice</a> is an easy one to build.</p>

<p>In order to summarise the main insights of Orlova’s paper, and discuss some of its wider implications, we need a couple of preliminaries.</p>

<p style="padding-left:100px;"><u>Preliminaries</u></p>

<p>A network, like the one(s) above, is a pair \((N,G)\), where \(N=\{1,\dots,n\}\) is a set of nodes (or agents) and \(G\) is an adjacency matrix indicating the (undirected) links between the agents. Thus, \(G_{ij} \in \{0,1\}\) for all agents \(i,j \in N\), where \(G_{ij}=0\) means that there is no link between \(i\) and \(j\) (above, that they are not friends) and \(G_{ij}=1\) means that there is (above, that they are friends). For example, for the networks we’ve seen so far, we have \(N = \{A,B,C,D,E\}\) and \(G_{Ci} = 1\) for \(i \in \{A,B,D,E\}\). Collect in set \(N_{i}(G) = \{j \in N \ | \ G_{ij}=1\}\) all agents to which \(i\) is connected (above, is friends with) and let \(d_{i}\) denote the cardinality of (the number of members in) this set (above, the number of \(i\)’s friends). For instance, \(N_{C}(G) = \{A,B,D,E\}\) and \(d_{C}=4\). Each agent has one of two actions, denoted by \(x_{i} \in \{0,1\}\), and each agent has a preference for one of the two actions, denoted by \(\theta_{i} \in \{0,1\}\). The vectors \(\mathbf{x}\) and \(\mathbf{\theta}\) denote arbitrary action and preference profiles, respectively. For simplicity, the \(d_{i}\)-tuple \(\mathbf{x}_{N_{i}(G)}\) denotes the actions of \(i\)’s friends under \(\mathbf{x}\).</p>

<p>We can now define the interactional utility function Orlova works with. For any \(i \in N\), it has the following form (32):</p>

<p style="padding-left:100px;">\(u_{i}(\theta_{i}, x_{i}, \mathbf{x}_{N_{i}(G)}) = \sum_{j \in N_{i}(G)} \left( \delta \cdot \mathbb{1}_{x_{i}=x_{j}} + (1-\delta) \cdot (1 - \mathbb{1}_{x_{i}=x_{j}}) + \lambda \cdot \mathbb{1}_{x_{i}=\theta_{i}} \right)\)</p>

<p>Where \(\delta \in [0,1]\) is the ‘matching’ benefit (and \(1-\delta\) is the ‘mis-matching’ benefit) and \(\lambda \in [0,\infty)\) is the benefit an agent obtains from following their idiosyncratic preference. Here, \(\mathbb{1}_{x_{i}=x_{j}}\) is an indicator function that is equal to one when \(j\)’s action matches \(i\)’s, and zero otherwise. (And so \(1 - \mathbb{1}_{x_{i}=x_{j}}\) is equal to one when \(j\)’s action mis-matches \(i\)’s, and zero otherwise.) Similarly, \(\mathbb{1}_{x_{i}=\theta_{i}}\) is equal to one when \(i\)’s action matches her preference, and zero otherwise. When \(\lambda = 0\), we are in the canonical case where only network effects influence individual utility, while when \(\lambda\neq 0\), we are in the case of interactional utility where idiosyncratic preferences also play a role. Finally, when \(\delta > 1/2\), matching has a bigger (marginal) benefit than mismatching and so we are in the case of strategic complements; conversely, \(\delta < 1/2\) is the case of strategic substitutes. (Recall that, in the example above, we had \(\delta=1/3\) and \(\lambda=1/4\).)</p>

<p>Given this set-up, values for \(\delta\) and \(\lambda\) define distinct games, which is why Orlova refers to a game as \((\delta,\lambda\)). Furthermore, by introducing a tie-breaking rule, we may rule out mixed Nash equilibria, allowing us to focus on pure equilibria. Orlova does just that by requiring that whenever an agent is indifferent between two strategies, she go with her idiosyncratic preference. She calls this refined Nash equilibrium concept a <cite>selfish Nash equilibrium</cite> (32).</p>

<p>There are (at least) two types of situations that are particularly intriguing in this setting. First, equilibria where <cite>all</cite> agents adopt the same action—in Orlova’s words, these are <cite>homogeneous equilibria</cite> (otherwise, they are called <cite>heterogeneous</cite>). Second, equilibria where <cite>all</cite> agents adopt the action that coincides with their idiosyncratic preference—in Orlova’s words, these are <cite>fully satisfying equilibria</cite> (otherwise, they are called <cite>frustrating</cite>). For instance, in <smallcaps>figure 2</smallcaps>, both action profiles (on the left and right) are heterogeneous (since both actions, drink coffee and tea, are chosen by some agents) and frustrating (since there are some agents who do not adopt the action matching their preference). Conversely, the following figure illustrates (1) a homogeneous (and frustrating) action profile on the left, and (2) a fully satisfying (and heterogenous) action profile on the right.</p>

<p style="padding-left:100px;"><img src="https://uzunovam.github.io/images/graph3.png" /></p>

<p style="padding-left:100px;"><smallcaps>figure 3</smallcaps></p>



<p style="padding-left:100px;"><u>Coordination games</u></p>
<p>Consider first the case of <cite>coordination games</cite> where \(1/2 < \delta \leq 1\) and \(0 < \lambda < 2\delta -1\) (33). That is, in such games, (1) the matching benefit \(\delta\) is stronger than the mismatching benefit \(1-\delta\) and (2) the stronger the matching benefit \(\delta\) is (the closer it is to one), the wider the admissible range of idiosyncratic benefits \(\lambda\) is (conversely, the weaker \(\delta\) is, the smaller the admissible range of \(\lambda\) is). Notice, in particular, that \(2\delta - 1\) can be thought of as the ‘upper bound’ of the idiosyncratic benefit—in other words, for a game to be a coordination game, the strength of the idiosyncratic benefit should be bounded from above by the strength of the matching benefit. Consider the five-agent network illustrated so far, which we may describe by its degree distribution, that is, the distribution of connections (above, friends) that each player has. In our example, we have agents with a degree of \(1\) (agents \(D\) and \(E\)), \(2\) (agents \(A\) and \(B\)), and \(4\) (agent \(C\)). Notice that an agent’s utility here depends on how many of her neighbours perform the same action as she does and whether that action is her <cite>preferred</cite> action. Call an agent’s neighbour who performs her preferred action her <cite>companion</cite> (33). For example, in the left panel of <smallcaps>figure 2</smallcaps>, \(D\) is \(C\)’s companion (but not vice versa). We may then ask what the conditions for certain optimal actions are by first asking the following question: for a player \(i\) with a given degree \(d_{i}\), what is the minimum number of companions for the agent’s preferred action to be her optimal response? Notice that if we are interested in fully satisfying equilibria (where everyone performs her preferred action), the answer to this question is crucial. The answer for an arbitrary degree \(d_{i}\) is stated in Lemma 1 (36) and denoted by \(l^{*}_{\delta,\lambda}(d_{i})\). Here, we may apply it to our five-agent network.</p>

<p>Consider, first, the agents of degree \(1\) (agents \(D\) and \(E\)). For arbitrary \(\delta\) and \(\lambda\) that satisfy the coordination-game conditions, the minimum number of companions such agents need for their preferred action to be optimal is given by:</p>

<p style="padding-left:100px;">(1) \(l^{*}_{\delta,\lambda}(1) = \lambda + 2 \delta - 1\) when \((2\delta -1)\frac{1-2(2\delta-1)}{1+2(2\delta-1)} \leq \lambda < 2\delta-1\) (that is, when \(\lambda\) is sufficiently close to its upper bound);</p>

<p style="padding-left:100px;">(2) \(l^{*}_{\delta,\lambda}(1) = \lambda + 2 \delta\) when \(0 < \lambda < (2\delta -1)\frac{1-2(2\delta-1)}{1+2(2\delta-1)}\) (that is, when \(\lambda\) is sufficiently smaller than its upper bound).</p>

<p>For agents of degree \(2\) (agents \(A\) and \(B\)), we have:</p>

<p style="padding-left:100px;">(1) \(l^{*}_{\delta,\lambda}(2) = \lambda\) when \((2\delta -1)\frac{1}{2\delta} \leq \lambda < 2\delta-1\) (that is, when \(\lambda\) is sufficiently close to its upper bound);</p>

<p style="padding-left:100px;">(2) \(l^{*}_{\delta,\lambda}(2) = \lambda + 1\) when \(0 < \lambda < (2\delta -1)\frac{1}{2\delta}\) (that is, when \(\lambda\) is sufficiently smaller than its upper bound).</p>

And, finally, for agent \(C\) of degree \(4\), we have:
